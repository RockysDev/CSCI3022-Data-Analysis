{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI3022 S23\n",
    "\n",
    "\n",
    "\n",
    "# Homework 2: Measures of Centrality and Dispersion; Visualizing Data\n",
    "\n",
    "## Due Monday, January 30th at 11:59pm to Gradescope\n",
    "***\n",
    "\n",
    "**Name**: ________________________________________________________________________\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "### Collaboration Policy\n",
    "\n",
    "While completing the assignment you are not allowed to consult any source other than the course textbooks/online reference links provided on Canvas, your own class notes, and/or the posted lecture slides/in-class Jupyter notebooks.   You may discuss questions you have with your classmates or on Piazza or in office hours, but all work you submit must be your own, which means when writing up your solutions or code, you MUST do it entirely by yourself. \n",
    "\n",
    "You should be able to easily reproduce from scratch and explain a solution that was your own when asked in office hours by a TA/Instructor or on a quiz/exam without referencing your notes/book/HW.   \n",
    "\n",
    "\n",
    "**Do not search/ask for a solution online**: You may not actively search for a solution to the problems below from the internet. This includes posting to or using sources like ChatGPT, StackExchange, Reddit, Chegg, CourseHero, etc.  \n",
    "\n",
    "**We are here to help!  Visit HW Hours and/or post questions on Piazza!**\n",
    "\n",
    "\n",
    "Copying/consulting from the solution of another classmate or an online solution (or providing a classmate your solution) constitutes a **violation of the course's collaboration policy and the honor code and will result in an F in the course and a trip to the honor council**.   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Instructions for Submitting in Correct Format \n",
    "\n",
    "You must submit a PDF of this Juptyer notebook to Gradescope by the deadline listed above.  Submissions that are not a PDF or that are not submitted to Gradescope will not be counted for credit.  \n",
    "\n",
    "$\\color{red}{\\text{Before submitting your PDF, make sure that your LaTeX has rendered correctly in your PDF.}}$\n",
    "$\\color{red}{\\text{Any of your solutions with incorrectly rendered or incompletely rendered LaTeX will be given 0 points.}}$ \n",
    "\n",
    "- There are several ways to quickly make a .pdf out of this notebook for Gradescope submission.  \n",
    " \n",
    " - If you are running Juptyer locally on your computer: \n",
    " \n",
    "     - Option1 : Select Kernel->Restart & Run All. Use File ->  Print Preview, and then Right-Click -> Print using your default browser and \"Print to PDF\"\n",
    " \n",
    "     - Option 2: Select Kernel->Restart & Run All. Use File -> Download as PDF via LaTeX.  This will require your system path find a working install of a TeX compiler\n",
    " \n",
    " - If you are running using CSEL: \n",
    " \n",
    "     - Option1 :  Go to File ->Save & Export Notebook As-> HTML.  Then open the HTML, and then Right-Click -> Print and select \"Print to PDF\".  \n",
    "     - Option2 :  Go to File ->Download. Then use this converter https://htmtopdf.herokuapp.com/ipynbviewer/ to convert ipynb to pdf.\n",
    " \n",
    "### Notes\n",
    "- For full points you must correctly match your questions to the respective Gradescope problem, and include clear comments in your code.   Please note that any LaTeX that is not correctly rendered in your submitted PDF will result in a 0 on the entire problem(s) that involves the unrendered LaTeX. \n",
    "- For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- Any relevant data sets are available on Canvas. \n",
    "- LaTeX Tips:  Here is a [reference guide] (https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference).  **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "\n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (14 pts) Problem 1: Computation (Streaming Means)\n",
    "***\n",
    "\n",
    "Data science is often divided into two categories: questions of *what* the best value might be to represent a data problem, and questions of *how* to compute that data value.  Prior lectures should tell you that computing the mean is valuable!  But *how* do we compute the mean?\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "<a id='eq1'></a>\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2 \\qquad \\tag{Equation 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: (1 pt)\n",
    "\n",
    "How many computations - floating point operations: addition, subtraction, multiplication, division each count as 1 operation - are required to compute the **mean** of a data set with $n$ observations? (assume $n>1$).  Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: (2 pts)  \n",
    "i).  Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class ([Equation 1](#eq1)). \n",
    "\n",
    "ii).  Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class ([Equation 1](#eq1)). \n",
    "\n",
    "You may **not** use any built-in sample mean or variance functions.  Hint:  Try to do this without using any `for` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: (1 pt)  Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the minutes late that the BuffBus is running on Friday afternoon:\n",
    "\n",
    "`bus = [4, 10, 0, 312, 22, 39, 81, 19, 8, 60, 1,3,80, 42,12,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: (1 pt)\n",
    "\n",
    "Now suppose our data is streaming- we slowly add observations one at a time, instead of seeing the entire data set at once. We are still interested in the mean.\n",
    "\n",
    "Suppose we inefficiently recalculate the mean by brute force after each new observation is added to our data set. In this brute force calculation we do not save any information from previous mean calculations (for example, we would start by computing the mean of first two points, then when a 3rd data point is added we would recompute the mean of the first three datapoints (without using any information we gathered when calculating the mean of the first 2 data points), and so forth until we had compiled all $n$ means). \n",
    "\n",
    "How many floating point operations are spent computing (and re-computing) the $n$ means of a streaming data set of size $n$ in this inefficient brute force manner?  (Note that the mean of the first data point is just itself, so no floating-point computations are required to compute the first mean). \n",
    "\n",
    "Use formulas for summations from Calculus 2 (https://tutorial.math.lamar.edu/classes/calci/summationnotation.aspx)  to fully simplify your answer in closed form (i.e. without using sigma notation) in terms of $n$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be convinced that streaming a mean costs a lot more computer time than just computing once!\n",
    "\n",
    "In this problem we explore a smarter method for such an _online_ computation of the mean.  \n",
    "\n",
    "The following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "\n",
    "<a id='eq2'></a>\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "\\tag{Equation 2}\n",
    "$$\n",
    "\n",
    "\n",
    "**Part E**  (2 pts)\n",
    "Prove mathematically why Equation 2 is true using the definition(s) of $\\bar{x}_n$ and $\\bar{x}_{n-1}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: (2 pts)  Implement a third function called `update_mean` that implements Equation 2. Note that this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$, and returns $\\bar{x}_{n}$. A function header and return statement are provided for you. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mean(prev_mean, xn, n):\n",
    "    new_mean = #TO DO\n",
    "    return(new_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G** (2 pts) Use the function you created in Part F to compute the values that you get from finding the mean of the first two buff buses' lateness, then the mean first three buff buses' lateness, and so on up to all of the `bus` data points from **Part C**. Store your streaming bus means in a numpy array called `buffbus_bad_means`.  Report all 16 estimates in `buffbus_bad_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure your function complies with the given API, run this small test, where we suppose we have a mean of $\\bar{x}_n = 1$ with the first $2$ data points (`prev_mean`), and we update this with the 3rd ($n=3$) data point which is $x_3=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert update_mean(1,2,3)==4/3, \"Warning: function seems broken.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part H**: (1 pt)\n",
    "\n",
    "How many floating point operations were spent computing the 16 means in your code in part G? (Again you can assume that no floating point operations are required for the first mean).  Is this truly better than the uninformed approach from part D?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part I:** (2 pts)\n",
    "A similar result to the formula preceding part E holds for variance.  In particular, we can write that:\n",
    "\n",
    "$$\n",
    "\\displaystyle s^2 = \\frac{\\sum_{i=1}^n (x_i-\\bar{x})^2}{n-1} = \\frac{1}{n(n-1)} \\left(n \\cdot \\sum_{i=1}^n x_i^2 - \\left(\\sum_{i=1}^n x_i \\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "Describe in **words** and/or **psuedocode** how you might adapt the function you made in part **F** to perform running calculations of both variance and mean.  Be very clear as to what the input/instantiation arguments would be as well as what the output arguments would be in addition to any intermediate calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2  (13 pts):  Data Visualization; Means & Variances\n",
    "***\n",
    "\n",
    "For Problem 2 we are looking at the data from a study investigating school childrens' intelligence. The data consists of a random sample of 1500 participants and some of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the csv file, \"foot_smart.csv\".  Create a dataframe called `dfFootIQ` and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of this data Set\n",
    "\n",
    "This is a data set of 1500 participants. The participants are all children from 7 different schools. \n",
    "\n",
    "***foot_length:*** This is the length of the students foot in inches.\n",
    "\n",
    "***shoe_size:*** This is the size of the shoe worn by the student.\n",
    "\n",
    "***sex:*** This is the sex of the student: 0 female, 1 male.\n",
    "\n",
    "***IQ:*** This is a measure of intelligence as measured on a standard exam, scaled from 0 to 35.\n",
    "\n",
    "***US_section:*** This is the section of the U.S. that the student comes from.\n",
    "\n",
    "***city_size:*** This is the approximate size of the city (in thousands) from which the student came from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part a] (1 pt) Clean the data***\n",
    "\n",
    "Notice that `city_size` has data entered as '100K' for 100,000 and 1M for 1,000,000.\n",
    "\n",
    "Clean this column so that it holds integers such as 100000 and 1000000 instead of 100K and 1M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part b]*** Suppose we were to make a scatterplot for foot length and city size (`foot_length` and `city_size`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the code below and run it.\n",
    "\n",
    "#ax1 = dfFootIQ.plot.scatter(x=['foot_length'], y=['city_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note (i)*** The scatter plot has discrete values on the y-axis which makes the 'scatter plot' look like lines.\n",
    "\n",
    "***Note (ii)*** There is no discernible pattern. The city's of various sizes (on the y-axis) contain students with shoe sizes (on the x-axis) all across the shoe-size spectrum which means students of a particular shoe size do not tend to congregate in citys  of a particular size.\n",
    "\n",
    "This seems to be common sense; for instance, there is no reason why every student of shoe size 7 would come from a city of size 500,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make two more scatterplots:***\n",
    "\n",
    "   i] ***(0.5 points)*** A scatterplot for shoe_size and IQ\n",
    "\n",
    "   ii] ***(0.5 points)*** A scatterplot for foot_length and IQ\n",
    "\n",
    "iii] ***(1 point)*** Explain your findings. Either explain why no pattern is found, or if you detect a pattern, then explain why such a pattern exists between shoe size and intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your scatterplots for Part B here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explain your scatterplot findings for Part B here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part c]*** \n",
    "We're interested in investigating how the mean changes if you add or multiply each of the data points by a constant.  \n",
    "\n",
    "i).(0.5 pts)  Find the mean shoe size for the dfFootIQ data (you CAN use built-in functions to do this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii). (1 pt) In class, we proved what will happen to the mean if we add any constant $a$ to each data point.  First, explain what the new mean should be (in terms of $a$) based on what we derived in class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " iii). (1 pt)  Then show this via code for $a=2$, by actually adding 2 to each shoe size data point in dfFootIQ and calculating the new mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv). (1 pt)  What if we multiply each term by a constant $c$?  Prove mathematically what the new mean will be (in terms of $c$).  Use the definition of $\\bar{x}_n$ from ([Equation 1](#eq1)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v). (1 pt)  Then show this via code for $c=3$, by actually multiplying each shoe size data point in dfFootIQ by $3$ and calculating the new mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part d]***\n",
    "We're interested in investigating how the variance changes if you add or multiply each of the data points by a constant.  \n",
    "\n",
    "i). (0.5 pt)  Find the sample variance shoe size for the dfFootIQ data (you CAN use built-in functions to do this).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii). (1 pt)  In class, we proved what will happen to the variance if we add any constant $a$ to each data point.  First, explain what the new variance will be based on what we derived in class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii). (1 pt)  Then show this via code for $a=2$, by actually adding 2 to each shoe size data point and calculating the new variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv). (2 pts)  What if we multiply each term by a constant $c$?  Prove mathematically what the new variance will be (in terms of $c$).  Use the definition of $s_n^2$ from ([Equation 1](#eq1)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v). (1 pt) Then show this via code for $c=3$, by actually multiplying each shoe size data point in dfFootIQ by $3$ and calculating the new variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a id='p3'></a>\n",
    "\n",
    "## (23 pts) Problem 3: Practice (Titanic)\n",
    "*** \n",
    "The sinking of the RMS Titanic was a terrible tragedy that saw the loss of many lives. Even within this tragedy, thanks to the combinations of the records of the White Star Line and the thorough nature of follow-up research after the accident we have some records that can help us try to piece together the course of events on board the ship. Many of the historians and other researchers who have investigated this event have speculated as to what exactly happened.\n",
    "\n",
    "We have the data on survival rates by class, gender, and age, so let's figure out whether there is evidence for some of these scenarios. Access the Titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival (**Survived**), and gender (**Sex**) of passengers, among other things. Be sure to use the `titanic_data.csv` data set, *not* the `dirty_titanic_data` file from the in-class notebook exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset and take a look at it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: (2 pts) Use Pandas methods to create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. Be sure to show any exploratory work determining if/where there are rows with missing values. _HINT: There should be 714 rows in your cleaned data set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B** (1 pt):\n",
    "Based on the overall population of passengers, report the proportion that survived (round your answer to the nearest ten thousandth).\n",
    "\n",
    "$$P(Survived=1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C** (2 pts): \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours instead. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: (8 pts) \n",
    "Write code to compute the following:\n",
    "\n",
    "i).  What percent of males survived?  What percent of females survived?  \n",
    "ii).  What percent of first class travelers survived?  What about 2nd class?  What about third class?    \n",
    "iii).  Finally, compute the percent of survivors of men *within* each passenger class and then do the same for women (you should have 6 subsets).   \n",
    "\n",
    "iv).   Then, answer the following questions:\n",
    "* **(a)** When reviewing gender survival percentages, how do the results compare to the base survival percentage from **Part B**?\n",
    "* **(b)** When reviewing class survival percentages, how do the results compare to the base survival percentage from **Part B**?\n",
    "\n",
    "* **(c)** Within each passenger class, were men or women more/less/equally likely to survive?\n",
    "* **(d)**  Did men in first class or women in third class have a higher survival percentage?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: (2 pts) One might wonder how a passenger's age is related to the likelihood that they would survive the Titanic disaster. In addition to the \"male chivalry\" argument outlined above, you can perhaps imagine an addendum - \"women and children first!\" - as the cry to ring out across the decks. Or you might imagine the opposite - rather than \"class warfare\", it is simply healthy adults fighting to take lifeboat spots for themselves.\n",
    "\n",
    "\n",
    "i).  Calculate the median age of passengers who survived and compare it to the median age of those who did not.  You may use built-in function(s).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii).  Calculate the IQR for the ages of passengers who survived, and a separate IQR for the ages of passengers who did not.  The only built-in method you may use as part of your calculation is the `pandas.DataFrame.quantile`\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Part F** (2 pts)\n",
    "Create two side-by-side box and whisker plots comparing the ages of passengers who survived, and the ages of passengers who did not. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G** (3 pts) In addition to using boxplots, we can also visualize data using histograms.  \n",
    "Plot two stacked density histograms showing the distribution of the ages of passengers who survived, and the distribution of the ages of passengers who did not.  \n",
    "* Use the bin edges $[0,3,6,\\ldots,75,78,81]$ for both histograms.\n",
    "* Include a legend (`plt.legend` after `label=` on the histograms) and label your axes.\n",
    "* Comment on the results. How would you characterize each distribution? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Does your figure suggest that some age ranges are more or less likely to have survived the disaster than other ages? Fully explain your reasoning and use your figure to justify your conclusions.\n",
    "* If you noticed some relationship between age and likelihood of survival, what is one possible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part H: (1 pt)** In Part G, we plotted two *density* histograms, showing the distributions of ages of passengers that survived or did not survive the Titanic disaster. Why would it be misleading for us to have plotted these as *frequency* histograms instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part I** (2 pts) : Do the data suggest class warfare, male chivalry, age bias, or some combination of these characteristics in the final hours aboard the Titanic?  Justify your conclusions based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Answers To Selected Problems\n",
    "\n",
    "These are final answers for selected problems so you can check your work and determine if you are on the right track.  To receive credit on each problem you must show all steps leading to these answers, fully answer the problem, and justify your answer using correct mathematical notation.\n",
    "\n",
    "\n",
    "1D).  $\\frac{n^2+n-2}{2}$\n",
    "\n",
    "3B).  $39.08\\%$\n",
    "\n",
    "3D iii).  Your code should output 6 different percentages here.  One of these (to check your answer) should be that $13.8\\%$ of 3rd class males survived.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
